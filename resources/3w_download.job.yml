# Databricks job for downloading 3W dataset
# This job downloads parquet files from the Petrobras 3W dataset on GitHub
resources:
  jobs:
    3w_download_job:
      name: 3w_download_job

      # Job cluster configuration
      job_clusters:
        - job_cluster_key: download_cluster
          new_cluster:
            spark_version: "13.3.x-scala2.12"
            node_type_id: "i3.xlarge"
            num_workers: 0 # Single node for download task
            spark_conf:
              "spark.databricks.cluster.profile": "singleNode"
              "spark.master": "local[*]"
            custom_tags:
              "ResourceClass": "SingleNode"
              "Project": "HydratePrediction"
              "Purpose": "DataDownload"

      # Job parameters
      parameters:
        - name: test_mode
          default: "true"
        - name: config_path
          default: "config.yaml"

      # Email notifications (uncomment and configure as needed)
      #email_notifications:
      #  on_failure:
      #    - scott.mckean@databricks.com
      #  on_success:
      #    - scott.mckean@databricks.com

      # Timeout configuration
      timeout_seconds: 7200 # 2 hours max

      # Job tasks
      tasks:
        - task_key: download_3w_dataset
          job_cluster_key: download_cluster

          spark_python_task:
            python_file: "src/download_3w_job.py"
            parameters: []

          # Libraries needed for the job
          libraries:
            - pypi:
                package: "requests>=2.25.0"
            - pypi:
                package: "pyyaml>=6.0"
            - pypi:
                package: "pandas>=2.0.0"

      # Schedule (optional - uncomment to enable)
      # trigger:
      #   periodic:
      #     interval: 7
      #     unit: DAYS

      # Access control
      access_control_list:
        - user_name: scott.mckean@databricks.com
          permission_level: CAN_MANAGE
