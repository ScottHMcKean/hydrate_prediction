{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e543c262",
   "metadata": {},
   "source": [
    "# Agent Evaluation\n",
    "\n",
    "Now that we have our custom DIY Agent with ML tools, we can evaluate how the model is calling our tools and evaluate traces in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cd824a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/scott.mckean/Repos/hydrate_prediction/.venv/bin/python: No module named pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2ddd9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%sh` not found (But cell magic `%%sh` exists, did you mean that instead?).\n"
     ]
    }
   ],
   "source": [
    "%sh uv pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399df43e",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Evaluation Dataset\n",
    "\n",
    "You can edit the requests or expected responses in your evaluation dataset and run evaluation as you iterate your agent, leveraging mlflow to track the computed quality metrics.\n",
    "\n",
    "Evaluate your agent with one of our [predefined LLM scorers](https://learn.microsoft.com/azure/databricks/mlflow3/genai/eval-monitor/predefined-judge-scorers), or try adding [custom metrics](https://learn.microsoft.com/azure/databricks/mlflow3/genai/eval-monitor/custom-scorers).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daee47a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.genai.scorers import RelevanceToQuery, Safety, RetrievalRelevance, RetrievalGroundedness\n",
    "from databricks import agents\n",
    "\n",
    "eval_dataset = [\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"What are the predictions for well 15 for the next minute?\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \"expected_response\": None\n",
    "    }\n",
    "]\n",
    "\n",
    "eval_results = mlflow.genai.evaluate(\n",
    "    data=eval_dataset,\n",
    "    predict_fn=lambda messages: AGENT.predict({\"messages\": messages}),\n",
    "    scorers=[RelevanceToQuery(), Safety()], # add more scorers here if they're applicable\n",
    ")\n",
    "\n",
    "# Review the evaluation results in the MLfLow UI (see console output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6ffc2c",
   "metadata": {},
   "source": [
    "## Trace Evaluation\n",
    "\n",
    "One of the most powerful features of MLflow is the ability to trace the execution of a model. This allows us to see the exact inputs and outputs of a model, as well as the code that was used to train it. This is especially important for real tasks where an agent is calling an ML model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9198018",
   "metadata": {},
   "source": [
    "## Guidelines and Custom Scorers\n",
    "Correctness is great, but we often need much more granular information about how a model is doing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06ec8ed",
   "metadata": {},
   "source": [
    "## Feedback\n",
    "The Review App is a great way to capture feedback, but with `mlflow-tracing`, we can now capture feedback directly from users into a table."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
