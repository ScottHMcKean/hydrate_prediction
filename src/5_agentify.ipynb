{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e543c262",
   "metadata": {},
   "source": [
    "# Tool-calling Agent\n",
    "\n",
    "The agent code implements [MLflow's ChatAgent](https://mlflow.org/docs/latest/python_api/mlflow.pyfunc.html#mlflow.pyfunc.ChatAgent) interface, a Databricks-recommended open-source standard that simplifies authoring multi-turn conversational agents, and is fully compatible with Mosaic AI agent framework functionality.\n",
    "\n",
    "**_NOTE:_** This notebook uses LangChain, but AI Agent Framework is compatible with any agent authoring framework, including LlamaIndex or pure Python agents written with the OpenAI SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f6cd44",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cd824a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/scott.mckean/Repos/hydrate_prediction/.venv/bin/python: No module named pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2ddd9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%sh` not found (But cell magic `%%sh` exists, did you mean that instead?).\n"
     ]
    }
   ],
   "source": [
    "%sh uv pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980802f8",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54381f0b",
   "metadata": {},
   "source": [
    "We could use something like Genie to talk with out data, but when the structures are simple, it makes sense to use a more lightweight approach. This is a simple example of using a SQL query as a tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0238e122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydrate.utils import DotConfig\n",
    "config = DotConfig('config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee8165c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    CREATE OR REPLACE FUNCTION shm.3w.filter_well_data(\n",
    "        p_well_number INT COMMENT 'well number',\n",
    "        p_num_minutes INT COMMENT 'number of minutes'\n",
    "    )\n",
    "    RETURNS TABLE (\n",
    "        `T-JUS-CKP` DOUBLE,\n",
    "        `T-TPT` DOUBLE,\n",
    "        `P-TPT` DOUBLE,\n",
    "        `P-MON-CKP` DOUBLE,\n",
    "        `P-PDG` DOUBLE,\n",
    "        timestamp TIMESTAMP\n",
    "    )\n",
    "    RETURN\n",
    "    SELECT\n",
    "        `T-JUS-CKP`,\n",
    "        `T-TPT`,\n",
    "        `P-TPT`,\n",
    "        `P-MON-CKP`,\n",
    "        `P-PDG`,\n",
    "        timestamp\n",
    "    FROM (\n",
    "    SELECT\n",
    "        *,\n",
    "        MAX(timestamp) OVER (PARTITION BY well_number) AS max_ts\n",
    "    FROM shm.3w.well_data\n",
    "    )\n",
    "    WHERE well_number = p_well_number\n",
    "    AND timestamp >= date_add(MINUTE, -p_num_minutes, max_ts)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3853540",
   "metadata": {},
   "source": [
    "## Agent\n",
    "\n",
    "Let's test the agent. Since this notebook called `mlflow.langchain.autolog()` you can view the trace for each step the agent takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad561fed",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'databricks_langchain'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AGENT\n\u001b[32m      2\u001b[39m AGENT.predict({\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [{\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mHello!\u001b[39m\u001b[33m\"\u001b[39m}]})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/hydrate_prediction/agent.py:4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Generator, Optional, Sequence, Union\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatabricks_langchain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      5\u001b[39m     ChatDatabricks,\n\u001b[32m      6\u001b[39m     VectorSearchRetrieverTool,\n\u001b[32m      7\u001b[39m     DatabricksFunctionClient,\n\u001b[32m      8\u001b[39m     UCFunctionToolkit,\n\u001b[32m      9\u001b[39m     set_uc_function_client,\n\u001b[32m     10\u001b[39m )\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlanguage_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LanguageModelLike\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunnables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RunnableConfig, RunnableLambda\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'databricks_langchain'"
     ]
    }
   ],
   "source": [
    "from agent import AGENT\n",
    "AGENT.predict({\"messages\": [{\"role\": \"user\", \"content\": \"Hello!\"}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c029256",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in AGENT.predict_stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is 5+5 in python\"}]}\n",
    "):\n",
    "    print(event, \"-----------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c83e4b",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Log the agent as an MLflow model\n",
    "\n",
    "Determine Databricks resources to specify for automatic auth passthrough at deployment time\n",
    "- **TODO**: If your Unity Catalog Function queries a [vector search index](https://learn.microsoft.com/azure/databricks/generative-ai/agent-framework/unstructured-retrieval-tools) or leverages [external functions](https://learn.microsoft.com/azure/databricks/generative-ai/agent-framework/external-connection-tools), you need to include the dependent vector search index and UC connection objects, respectively, as resources. See [docs](https://learn.microsoft.com/azure/databricks/generative-ai/agent-framework/log-agent#specify-resources-for-automatic-authentication-passthrough) for more details.\n",
    "\n",
    "Log the agent as code from the `agent.py` file. See [MLflow - Models from Code](https://mlflow.org/docs/latest/models.html#models-from-code).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af445294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine Databricks resources to specify for automatic auth passthrough at deployment time\n",
    "import mlflow\n",
    "from agent import LLM_ENDPOINT_NAME, tools\n",
    "from databricks_langchain import VectorSearchRetrieverTool\n",
    "from mlflow.models.resources import DatabricksFunction, DatabricksServingEndpoint\n",
    "from pkg_resources import get_distribution\n",
    "from unitycatalog.ai.langchain.toolkit import UnityCatalogTool\n",
    "\n",
    "resources = [DatabricksServingEndpoint(endpoint_name=LLM_ENDPOINT_NAME)]\n",
    "for tool in tools:\n",
    "    if isinstance(tool, VectorSearchRetrieverTool):\n",
    "        resources.extend(tool.resources)\n",
    "    elif isinstance(tool, UnityCatalogTool):\n",
    "        # TODO: If the UC function includes dependencies like external connection or vector search, please include them manually.\n",
    "        # See the TODO in the markdown above for more information.\n",
    "        resources.append(DatabricksFunction(function_name=tool.uc_function_name))\n",
    "\n",
    "input_example = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What are the predictions for well 15 for the next minute?\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        name=\"agent\",\n",
    "        python_model=\"agent.py\",\n",
    "        input_example=input_example,\n",
    "        resources=resources,\n",
    "        pip_requirements=[\n",
    "            f\"databricks-connect=={get_distribution('databricks-connect').version}\",\n",
    "            f\"mlflow=={get_distribution('mlflow').version}\",\n",
    "            f\"databricks-langchain=={get_distribution('databricks-langchain').version}\",\n",
    "            f\"langgraph=={get_distribution('langgraph').version}\",\n",
    "        ],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399df43e",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Evaluate the Agent\n",
    "\n",
    "You can edit the requests or expected responses in your evaluation dataset and run evaluation as you iterate your agent, leveraging mlflow to track the computed quality metrics.\n",
    "\n",
    "Evaluate your agent with one of our [predefined LLM scorers](https://learn.microsoft.com/azure/databricks/mlflow3/genai/eval-monitor/predefined-judge-scorers), or try adding [custom metrics](https://learn.microsoft.com/azure/databricks/mlflow3/genai/eval-monitor/custom-scorers).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daee47a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.genai.scorers import RelevanceToQuery, Safety, RetrievalRelevance, RetrievalGroundedness\n",
    "from databricks import agents\n",
    "\n",
    "eval_dataset = [\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"What are the predictions for well 15 for the next minute?\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \"expected_response\": None\n",
    "    }\n",
    "]\n",
    "\n",
    "eval_results = mlflow.genai.evaluate(\n",
    "    data=eval_dataset,\n",
    "    predict_fn=lambda messages: AGENT.predict({\"messages\": messages}),\n",
    "    scorers=[RelevanceToQuery(), Safety()], # add more scorers here if they're applicable\n",
    ")\n",
    "\n",
    "# Review the evaluation results in the MLfLow UI (see console output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e98748",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Perform pre-deployment validation of the agent\n",
    "\n",
    "Before registering and deploying the agent, we perform pre-deployment checks via the [mlflow.models.predict()](https://mlflow.org/docs/latest/python_api/mlflow.models.html#mlflow.models.predict) API. See [documentation](https://learn.microsoft.com/azure/databricks/machine-learning/model-serving/model-serving-debug#validate-inputs) for details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1506b9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.models.predict(\n",
    "    model_uri=f\"runs:/{logged_agent_info.run_id}/agent\",\n",
    "    input_data={\"messages\": [{\"role\": \"user\", \"content\": \"Hello!\"}]},\n",
    "    env_manager=\"uv\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d3c722",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Register and Deploy the Agent\n",
    "\n",
    "Once we register the model to Unity Catalog, serving it becomes quite simple. See [docs](https://learn.microsoft.com/azure/databricks/generative-ai/deploy-agent) for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ce11cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "UC_MODEL_NAME = f\"{config.catalog}.{config.schema}.{config.agentify.agent_name}\"\n",
    "\n",
    "# register the model to UC\n",
    "uc_registered_model_info = mlflow.register_model(\n",
    "    model_uri=logged_agent_info.model_uri, name=UC_MODEL_NAME\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f115ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agents.deploy(UC_MODEL_NAME, uc_registered_model_info.version, tags = {\"endpointSource\": \"playground\"})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
