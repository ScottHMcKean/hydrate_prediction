{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddf2ea9d",
   "metadata": {},
   "source": [
    "# Train\n",
    "\n",
    "This notebook trains a lightgbm model on the 3W dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "015578be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydrate.utils import get_config_path, DotConfig\n",
    "config_path = get_config_path()\n",
    "config = DotConfig(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c730937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks.connect import DatabricksSession as SparkSession\n",
    "spark = SparkSession.builder.serverless(True).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bfa16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.table(f\"{config.catalog}.{config.schema}.{config.process.table}\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0fdb196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'tag': 'P-PDG', 'name': 'Pressure at the PDG', 'unit': 'Pa'},\n",
       " 2: {'tag': 'P-TPT', 'name': 'Pressure at the TPT', 'unit': 'Pa'},\n",
       " 3: {'tag': 'T-TPT', 'name': 'Temperature at the TPT', 'unit': 'degC'},\n",
       " 4: {'tag': 'P-MON-CKP', 'name': 'Pressure upstream of the PCK', 'unit': 'Pa'},\n",
       " 5: {'tag': 'T-JUS-CKP',\n",
       "  'name': 'Temperature downstream of the PCK',\n",
       "  'unit': 'degC'},\n",
       " 6: {'tag': 'P-JUS-CKGL',\n",
       "  'name': 'Pressure downstream of the GLCK',\n",
       "  'unit': 'Pa'},\n",
       " 7: {'tag': 'QGL', 'name': 'Gas lift flow rate', 'unit': 'sm^3/s'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.train.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "548eaff7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tag_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m indices = [\u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mwell_number\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m tags = [x[\u001b[33m'\u001b[39m\u001b[33mtag\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtag_info\u001b[49m.values()]\n\u001b[32m      3\u001b[39m target = [\u001b[33m'\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      5\u001b[39m ml_df = (\n\u001b[32m      6\u001b[39m     df[tags + indices + target]\n\u001b[32m      7\u001b[39m     .sort_values([\u001b[33m'\u001b[39m\u001b[33mwell_number\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m     .copy()\n\u001b[32m     11\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'tag_info' is not defined"
     ]
    }
   ],
   "source": [
    "indices = ['timestamp', 'well_number']\n",
    "tags = [x['tag'] for x in tag_info.values()]\n",
    "target = ['state']\n",
    "\n",
    "ml_df = (\n",
    "    df[tags + indices + target]\n",
    "    .sort_values(['well_number','timestamp'])\n",
    "    .ffill()\n",
    "    .dropna()\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "X_df = ml_df[tags]\n",
    "y_df = ml_df[target]\n",
    "\n",
    "X_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee8165c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    state\n",
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "..    ...\n",
       "95      0\n",
       "96      0\n",
       "97      0\n",
       "98      0\n",
       "99      0\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create binary hydrate target (state 8 = hydrate)\n",
    "ml_df['is_hydrate'] = (ml_df['state'] == 8).astype(int)\n",
    "\n",
    "print(\"Target distribution:\")\n",
    "print(ml_df['is_hydrate'].value_counts())\n",
    "print(f\"Hydrate prevalence: {ml_df['is_hydrate'].mean():.3f}\")\n",
    "\n",
    "# Check data distribution by well and state\n",
    "print(\"\\nStates present by well:\")\n",
    "state_by_well = ml_df.groupby('well_number')['state'].unique().apply(sorted)\n",
    "for well, states in state_by_well.items():\n",
    "    state_names_list = [state_names[s] for s in states]\n",
    "    print(f\"Well {well}: states {states} ({state_names_list})\")\n",
    "\n",
    "ml_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0c0d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for feature extraction: (100, 5)\n",
      "Wells: 1\n",
      "Time range: 2017-08-09 16:00:26 to 2017-08-09 16:02:05\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.feature_extraction import MinimalFCParameters\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Prepare data for TSFresh - need well_number as id and timestamp sorted\n",
    "tsfresh_df = ml_df[['well_number', 'timestamp'] + tags + ['state']].copy()\n",
    "tsfresh_df = tsfresh_df.sort_values(['well_number', 'timestamp']).reset_index(drop=True)\n",
    "\n",
    "print(f\"Data shape for feature extraction: {tsfresh_df.shape}\")\n",
    "print(f\"Wells: {tsfresh_df['well_number'].nunique()}\")\n",
    "print(f\"Time range: {tsfresh_df['timestamp'].min()} to {tsfresh_df['timestamp'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90bf2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tsfresh.feature_extraction.settings:Dependency not available for matrix_profile, this feature will be disabled!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting time series features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scott.mckean/Repos/hydrate_prediction/.venv/lib/python3.12/site-packages/tsfresh/__init__.py:12: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "Feature Extraction:   0%|          | 0/2 [00:00<?, ?it/s]/Users/scott.mckean/Repos/hydrate_prediction/.venv/lib/python3.12/site-packages/tsfresh/__init__.py:12: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "/Users/scott.mckean/Repos/hydrate_prediction/.venv/lib/python3.12/site-packages/tsfresh/__init__.py:12: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "/Users/scott.mckean/Repos/hydrate_prediction/.venv/lib/python3.12/site-packages/tsfresh/__init__.py:12: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "/Users/scott.mckean/Repos/hydrate_prediction/.venv/lib/python3.12/site-packages/tsfresh/__init__.py:12: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "/Users/scott.mckean/Repos/hydrate_prediction/.venv/lib/python3.12/site-packages/tsfresh/__init__.py:12: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "Feature Extraction: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted features shape: (1, 20)\n",
      "Number of features per tag: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract time series features using TSFresh with minimal feature set\n",
    "# Use minimal parameters for speed - we can expand later\n",
    "feature_extraction_settings = MinimalFCParameters()\n",
    "\n",
    "# Extract features for each tag\n",
    "print(\"Extracting time series features...\")\n",
    "features = extract_features(\n",
    "    tsfresh_df[['well_number', 'timestamp'] + tags],\n",
    "    column_id='well_number',\n",
    "    column_sort='timestamp',\n",
    "    default_fc_parameters=feature_extraction_settings,\n",
    "    disable_progressbar=False\n",
    ")\n",
    "\n",
    "print(f\"Extracted features shape: {features.shape}\")\n",
    "print(f\"Number of features per tag: {features.shape[1] // len(tags)}\")\n",
    "\n",
    "# Create multiclass target series aligned with features (one value per well)\n",
    "# Use the most frequent state for each well (mode)\n",
    "target_by_well = tsfresh_df.groupby('well_number')['state'].agg(lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else x.iloc[-1])\n",
    "y = target_by_well.loc[features.index]\n",
    "\n",
    "print(f\"Target distribution: {y.value_counts().sort_index().to_dict()}\")\n",
    "print(f\"Target classes: {sorted(y.unique())}\")\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e0cda1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=1, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Handle missing values and split data\u001b[39;00m\n\u001b[32m      2\u001b[39m X = features.fillna(\u001b[32m0\u001b[39m)  \u001b[38;5;66;03m# Simple imputation - can improve later\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m X_train, X_test, y_train, y_test = \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstratify\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining set: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_train.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, positive rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_train.mean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTest set: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_test.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, positive rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_test.mean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/hydrate_prediction/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/hydrate_prediction/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:2919\u001b[39m, in \u001b[36mtrain_test_split\u001b[39m\u001b[34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[39m\n\u001b[32m   2916\u001b[39m arrays = indexable(*arrays)\n\u001b[32m   2918\u001b[39m n_samples = _num_samples(arrays[\u001b[32m0\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m2919\u001b[39m n_train, n_test = \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.25\u001b[39;49m\n\u001b[32m   2921\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2923\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m   2924\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/hydrate_prediction/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:2499\u001b[39m, in \u001b[36m_validate_shuffle_split\u001b[39m\u001b[34m(n_samples, test_size, train_size, default_test_size)\u001b[39m\n\u001b[32m   2496\u001b[39m n_train, n_test = \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[32m   2498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_train == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2499\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2500\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2501\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2502\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33maforementioned parameters.\u001b[39m\u001b[33m\"\u001b[39m.format(n_samples, test_size, train_size)\n\u001b[32m   2503\u001b[39m     )\n\u001b[32m   2505\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[31mValueError\u001b[39m: With n_samples=1, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "# Handle missing values and split data\n",
    "X = features.fillna(0)  # Simple imputation - can improve later\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"Training classes: {sorted(y_train.unique())}\")\n",
    "print(f\"Test classes: {sorted(y_test.unique())}\")\n",
    "\n",
    "# Train LightGBM model for multiclass classification\n",
    "print(\"\\nTraining LightGBM model...\")\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    metric='multi_logloss',\n",
    "    boosting_type='gbdt',\n",
    "    num_leaves=31,\n",
    "    learning_rate=0.1,\n",
    "    feature_fraction=0.8,\n",
    "    bagging_fraction=0.8,\n",
    "    bagging_freq=5,\n",
    "    verbose=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lgb_model.fit(X_train, y_train)\n",
    "print(\"Model training completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6600dd44",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lgb_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Evaluate model performance\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m y_pred = \u001b[43mlgb_model\u001b[49m.predict(X_test)\n\u001b[32m      3\u001b[39m y_pred_proba = lgb_model.predict_proba(X_test)[:, \u001b[32m1\u001b[39m]\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== Model Performance ===\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'lgb_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate model performance\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "y_pred = lgb_model.predict(X_test)\n",
    "y_pred_proba = lgb_model.predict_proba(X_test)\n",
    "\n",
    "print(\"=== Model Performance ===\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[f\"State_{i}\" for i in sorted(y.unique())]))\n",
    "\n",
    "# Multiclass ROC-AUC (one-vs-rest)\n",
    "try:\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average='weighted')\n",
    "    print(f\"\\nWeighted ROC-AUC Score (OvR): {auc_score:.4f}\")\n",
    "except:\n",
    "    print(\"\\nROC-AUC not calculated (insufficient classes in test set)\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': lgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\n=== Top 10 Most Important Features ===\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "# Show some predictions with state names\n",
    "print(\"\\n=== Sample Predictions ===\")\n",
    "state_names = {\n",
    "    0: 'Normal', 1: 'Abrupt Increase of BSW', 2: 'Spurious Closure of DHSV',\n",
    "    3: 'Severe Slugging', 4: 'Flow Instability', 5: 'Rapid Productivity Loss',\n",
    "    6: 'Quick Restriction in PCK', 7: 'Scaling in PCK', 8: 'Hydrate in Production Line'\n",
    "}\n",
    "\n",
    "sample_results = pd.DataFrame({\n",
    "    'actual': y_test.iloc[:10],\n",
    "    'predicted': y_pred[:10],\n",
    "    'actual_name': y_test.iloc[:10].map(state_names),\n",
    "    'predicted_name': pd.Series(y_pred[:10]).map(state_names),\n",
    "    'max_probability': np.max(y_pred_proba[:10], axis=1)\n",
    "})\n",
    "print(sample_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
